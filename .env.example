# The transport for the MCP server - either 'sse' or 'stdio' (defaults to sse if left empty)
TRANSPORT=

# Host to bind to if using sse as the transport (leave empty if using stdio)
HOST=

# Port to listen on if using sse as the transport (leave empty if using stdio)
PORT=

# PostgreSQL database connection string for direct use with pgvector
# Format: postgresql://username:password@host:port/database
DATABASE_URL=postgresql://username:password@localhost:5432/your_database

# OLLAMA model settings (for local LLM inference)
# For Mistral, use "mistral" or your preferred tag (e.g., "mistral:latest")
OLLAMA_MODEL=mistral
# If running Ollama locally, use http://localhost:11434
OLLAMA_BASE_URL=http://localhost:11434

# Get your OpenAI API Key by following these instructions -
# https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# This is for fallback embedding/LLM if you want to use OpenAI
OPENAI_API_KEY=

# The LLM you want to use for summaries/contextual embeddings ("ollama" or "openai")
# If using Ollama, set to "ollama"
MODEL_CHOICE=ollama

# RAG strategies - set these to "true" or "false" (default to "false")
# USE_CONTEXTUAL_EMBEDDINGS: Enhances embeddings with contextual information for better retrieval
USE_CONTEXTUAL_EMBEDDINGS=false

# USE_HYBRID_SEARCH: Combines vector similarity search with keyword search for better results
USE_HYBRID_SEARCH=false

# USE_AGENTIC_RAG: Enables code example extraction, storage, and specialized code search functionality
USE_AGENTIC_RAG=false

# USE_RERANKING: Applies cross-encoder reranking to improve search result relevance
USE_RERANKING=false
